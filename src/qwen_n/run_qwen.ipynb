{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-23T09:29:47.333090Z",
     "start_time": "2025-12-23T09:29:46.441157Z"
    }
   },
   "source": [
    "from qwen3_model import Qwen3Model, load_weight\n",
    "from qwen3_tok import Qwen3Tokenizer, load_tokenizer\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:29:47.920003Z",
     "start_time": "2025-12-23T09:29:47.895704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"huggingface_hub\",  # to download pretrained weights\n",
    "    \"tokenizers\",       # to implement the tokenizer\n",
    "    \"torch\",            # to implement the model\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ],
   "id": "4cc86737eedda7de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface_hub version: 1.2.3\n",
      "tokenizers version: 0.22.1\n",
      "torch version: 2.9.1\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:29:48.982773Z",
     "start_time": "2025-12-23T09:29:48.974507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select which model to use via the following flag; only one can be True\n",
    "\n",
    "USE_BASE_MODEL = False\n",
    "USE_REASONING_MODEL = True\n",
    "USE_INSTRUCT_MODEL = False\n",
    "\n",
    "if (USE_BASE_MODEL + USE_REASONING_MODEL\n",
    "    + USE_INSTRUCT_MODEL) != 1:\n",
    "    raise AttributeError(\"Only one of the options above can be True.\")"
   ],
   "id": "be0b2addaa0d4932",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:29:50.064616Z",
     "start_time": "2025-12-23T09:29:50.057991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CHOOSE_MODEL = \"0.6B\"\n",
    "\n",
    "QWEN3_CONFIG = {\n",
    "        \"vocab_size\": 151_936,           # Vocabulary size\n",
    "        \"context_length\": 40_960,        # Context length that was used to train the model\n",
    "        \"emb_dim\": 1024,                 # Embedding dimension\n",
    "        \"n_heads\": 16,                   # Number of attention heads\n",
    "        \"n_layers\": 28,                  # Number of layers\n",
    "        \"hidden_dim\": 3072,              # Size of the intermediate dimension in FeedForward\n",
    "        \"head_dim\": 128,                 # Size of the heads in GQA\n",
    "        \"qk_norm\": True,                 # Whether to normalize queries and keys in GQA\n",
    "        \"n_kv_groups\": 8,                # Key-Value groups for grouped-query attention\n",
    "        \"rope_base\": 1_000_000.0,        # The base in RoPE's \"theta\"\n",
    "        \"dtype\": torch.bfloat16,         # Lower-precision dtype to reduce memory usage\n",
    "    }"
   ],
   "id": "91ccbf4094ccbb79",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:29:53.887776Z",
     "start_time": "2025-12-23T09:29:51.621951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qwen3_model import Qwen3Model\n",
    "torch.manual_seed(18)\n",
    "model = Qwen3Model(QWEN3_CONFIG)"
   ],
   "id": "aacaf7cdf20f04dd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:29:56.877768Z",
     "start_time": "2025-12-23T09:29:56.681653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(device)"
   ],
   "id": "a18992385b45e8e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3Model(\n",
       "  (tok_emb): Embedding(151936, 1024)\n",
       "  (trf_blocks): ModuleList(\n",
       "    (0-27): 28 x TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        (q_norm): RMSNorm()\n",
       "        (k_norm): RMSNorm()\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (fc2): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (fc3): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm()\n",
       "      (norm2): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (final_norm): RMSNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:29:58.976113Z",
     "start_time": "2025-12-23T09:29:58.969924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from safetensors.torch import load_file\n",
    "from huggingface_hub import hf_hub_download, snapshot_download"
   ],
   "id": "2f4a846d3a37835",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:01:00.678096Z",
     "start_time": "2025-12-23T11:00:58.649523Z"
    }
   },
   "cell_type": "code",
   "source": "load_weight(model, device, QWEN3_CONFIG, CHOOSE_MODEL)",
   "id": "6963c1dedf2a1c2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:01:03.437867Z",
     "start_time": "2025-12-23T11:01:03.006579Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = load_tokenizer(CHOOSE_MODEL)",
   "id": "ce779f956149563b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:01:04.671574Z",
     "start_time": "2025-12-23T11:01:04.661706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_text_basic_stream(model, token_ids, max_new_tokens, eos_token_id=None):\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            out = model(token_ids)[:, -1]\n",
    "            next_token = torch.argmax(out, dim=-1, keepdim=True)\n",
    "\n",
    "            if (eos_token_id is not None\n",
    "                   and torch.all(next_token == eos_token_id)):\n",
    "               break\n",
    "\n",
    "            yield next_token\n",
    "\n",
    "            token_ids = torch.cat([token_ids, next_token], dim=1)"
   ],
   "id": "77bc946b776e5623",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:01:49.789852Z",
     "start_time": "2025-12-23T11:01:05.955239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p = \"How can I breath under water ?\"\n",
    "input_token_ids = tokenizer.encode(p)\n",
    "input_token_ids_tensor = torch.tensor(input_token_ids, device=device).unsqueeze(0)\n",
    "\n",
    "\n",
    "for token in generate_text_basic_stream(\n",
    "    model=model,\n",
    "    token_ids=input_token_ids_tensor,\n",
    "    max_new_tokens=500,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    "):\n",
    "    token_id = token.squeeze(0).tolist()\n",
    "    print(\n",
    "        tokenizer.decode(token_id),\n",
    "        end=\"\",\n",
    "        flush=True\n",
    "    )"
   ],
   "id": "37eb820d2f0a951b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking, \"How can I breathe under water?\" Hmm, that's a bit of a trick question. Let me think about this.\n",
      "\n",
      "First, I need to consider the context. The user might be referring to a situation where they are underwater, like in a pool or a diving scenario. But the question is phrased as a question, not a statement. So maybe they're confused or looking for a way to breathe underwater, which is a common misconception.\n",
      "\n",
      "In reality, humans can't breathe underwater because the water is too dense and the pressure is too high. The body's lungs can't handle the pressure, so breathing underwater is impossible. However, there are some ways people might try to breathe underwater, like using a snorkel or a diving bell. But those are not actual methods of breathing. The user might be looking for a different answer, perhaps a humorous or unexpected one.\n",
      "\n",
      "I should explain that breathing underwater is not possible and maybe provide some alternative ways to breathe, like through the nose or mouth, which are common. Also, mention that the question might be a trick or a play on words. Let me make sure the answer is clear and addresses the user's possible confusion.\n",
      "</think>\n",
      "\n",
      "Breathe underwater is not possible because the water is too dense and the pressure is too high. The human body cannot handle the increased pressure, so you cannot breathe underwater. However, if you're referring to a trick question, you might be thinking of a scenario where you're underwater and trying to \"breathe\" in a way that's not physically feasible. For example, using a snorkel or diving bell is a common method, but those are not actual breathing techniques. Let me know if you'd like further clarification!"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5bfa54a6725d68aa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
