{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-23T09:29:47.333090Z",
     "start_time": "2025-12-23T09:29:46.441157Z"
    }
   },
   "source": [
    "from qwen3_model import Qwen3Model, load_weight\n",
    "from qwen3_tok import Qwen3Tokenizer, load_tokenizer\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:29:47.920003Z",
     "start_time": "2025-12-23T09:29:47.895704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"huggingface_hub\",  # to download pretrained weights\n",
    "    \"tokenizers\",       # to implement the tokenizer\n",
    "    \"torch\",            # to implement the model\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ],
   "id": "4cc86737eedda7de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface_hub version: 1.2.3\n",
      "tokenizers version: 0.22.1\n",
      "torch version: 2.9.1\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:29:48.982773Z",
     "start_time": "2025-12-23T09:29:48.974507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select which model to use via the following flag; only one can be True\n",
    "\n",
    "USE_BASE_MODEL = False\n",
    "USE_REASONING_MODEL = True\n",
    "USE_INSTRUCT_MODEL = False\n",
    "\n",
    "if (USE_BASE_MODEL + USE_REASONING_MODEL\n",
    "    + USE_INSTRUCT_MODEL) != 1:\n",
    "    raise AttributeError(\"Only one of the options above can be True.\")"
   ],
   "id": "be0b2addaa0d4932",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:29:50.064616Z",
     "start_time": "2025-12-23T09:29:50.057991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CHOOSE_MODEL = \"0.6B\"\n",
    "\n",
    "QWEN3_CONFIG = {\n",
    "        \"vocab_size\": 151_936,           # Vocabulary size\n",
    "        \"context_length\": 40_960,        # Context length that was used to train the model\n",
    "        \"emb_dim\": 1024,                 # Embedding dimension\n",
    "        \"n_heads\": 16,                   # Number of attention heads\n",
    "        \"n_layers\": 28,                  # Number of layers\n",
    "        \"hidden_dim\": 3072,              # Size of the intermediate dimension in FeedForward\n",
    "        \"head_dim\": 128,                 # Size of the heads in GQA\n",
    "        \"qk_norm\": True,                 # Whether to normalize queries and keys in GQA\n",
    "        \"n_kv_groups\": 8,                # Key-Value groups for grouped-query attention\n",
    "        \"rope_base\": 1_000_000.0,        # The base in RoPE's \"theta\"\n",
    "        \"dtype\": torch.bfloat16,         # Lower-precision dtype to reduce memory usage\n",
    "    }"
   ],
   "id": "91ccbf4094ccbb79",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:29:53.887776Z",
     "start_time": "2025-12-23T09:29:51.621951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qwen3_model import Qwen3Model\n",
    "torch.manual_seed(18)\n",
    "model = Qwen3Model(QWEN3_CONFIG)"
   ],
   "id": "aacaf7cdf20f04dd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:29:56.877768Z",
     "start_time": "2025-12-23T09:29:56.681653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(device)"
   ],
   "id": "a18992385b45e8e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3Model(\n",
       "  (tok_emb): Embedding(151936, 1024)\n",
       "  (trf_blocks): ModuleList(\n",
       "    (0-27): 28 x TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        (q_norm): RMSNorm()\n",
       "        (k_norm): RMSNorm()\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (fc2): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (fc3): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm()\n",
       "      (norm2): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (final_norm): RMSNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:29:58.976113Z",
     "start_time": "2025-12-23T09:29:58.969924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from safetensors.torch import load_file\n",
    "from huggingface_hub import hf_hub_download, snapshot_download"
   ],
   "id": "2f4a846d3a37835",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:01:00.678096Z",
     "start_time": "2025-12-23T11:00:58.649523Z"
    }
   },
   "cell_type": "code",
   "source": "load_weight(model, device, QWEN3_CONFIG, CHOOSE_MODEL)",
   "id": "6963c1dedf2a1c2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:01:03.437867Z",
     "start_time": "2025-12-23T11:01:03.006579Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = load_tokenizer(CHOOSE_MODEL)",
   "id": "ce779f956149563b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:01:04.671574Z",
     "start_time": "2025-12-23T11:01:04.661706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_text_basic_stream(model, token_ids, max_new_tokens, eos_token_id=None):\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            out = model(token_ids)[:, -1]\n",
    "            next_token = torch.argmax(out, dim=-1, keepdim=True)\n",
    "\n",
    "            if (eos_token_id is not None\n",
    "                   and torch.all(next_token == eos_token_id)):\n",
    "               break\n",
    "\n",
    "            yield next_token\n",
    "\n",
    "            token_ids = torch.cat([token_ids, next_token], dim=1)"
   ],
   "id": "77bc946b776e5623",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T19:04:29.247293Z",
     "start_time": "2025-12-23T19:02:31.543701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p = \"How can I breath under water ?\"\n",
    "input_token_ids = tokenizer.encode(p)\n",
    "input_token_ids_tensor = torch.tensor(input_token_ids, device=device).unsqueeze(0)\n",
    "\n",
    "\n",
    "for token in generate_text_basic_stream(\n",
    "    model=model,\n",
    "    token_ids=input_token_ids_tensor,\n",
    "    max_new_tokens=500,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    "):\n",
    "    token_id = token.squeeze(0).tolist()\n",
    "    text = tokenizer.decode(token_id)\n",
    "    print(\n",
    "        tokenizer.decode(token_id),\n",
    "        end=\"\",\n",
    "        flush=True\n",
    "    )"
   ],
   "id": "37eb820d2f0a951b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 14\u001B[39m\n\u001B[32m     12\u001B[39m token_id = token.squeeze(\u001B[32m0\u001B[39m).tolist()\n\u001B[32m     13\u001B[39m text = tokenizer.decode(token_id)\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m \u001B[38;5;28mprint\u001B[39m(\n\u001B[32m     15\u001B[39m     tokenizer.decode(token_id),\n\u001B[32m     16\u001B[39m     end=\u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     17\u001B[39m     flush=\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m     18\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:1186\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_darwin_311_64.SafeCallWrapper.__call__\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:627\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:937\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:928\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:585\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.do_wait_suspend\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1195\u001B[39m, in \u001B[36mPyDB.do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[39m\n\u001B[32m   1192\u001B[39m         from_this_thread.append(frame_id)\n\u001B[32m   1194\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, stop_reason):\n\u001B[32m-> \u001B[39m\u001B[32m1195\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1210\u001B[39m, in \u001B[36mPyDB._do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[39m\n\u001B[32m   1207\u001B[39m             \u001B[38;5;28mself\u001B[39m._call_mpl_hook()\n\u001B[32m   1209\u001B[39m         \u001B[38;5;28mself\u001B[39m.process_internal_commands()\n\u001B[32m-> \u001B[39m\u001B[32m1210\u001B[39m         time.sleep(\u001B[32m0.01\u001B[39m)\n\u001B[32m   1212\u001B[39m \u001B[38;5;28mself\u001B[39m.cancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[32m   1214\u001B[39m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5bfa54a6725d68aa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
